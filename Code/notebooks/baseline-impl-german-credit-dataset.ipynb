{
 "cells": [
  {
   "metadata": {
    "id": "uOcS5s3VZKFq",
    "colab_type": "text",
    "_uuid": "6f9d55e2cd5792dc66d332ef3ccafde266046ce4"
   },
   "cell_type": "markdown",
   "source": "The German Credit data set is a publically available data set downloaded from the UCI Machine Learning Repository. The data contains data on 20 variables and the classification whether an applicant is considered a Good or a Bad credit risk for 1000 loan applicants.\n\n### [Data Source](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data))\n- Professor Dr. Hans Hofmann  \n- Institut f\"ur Statistik und \"Okonometrie  \n- Universit\"at Hamburg  \n- FB Wirtschaftswissenschaften  \n- Von-Melle-Park 5    \n- 2000 Hamburg 13\n\n### Benchmark\n![Credit Risk Classification: Faster Machine Learning with Intel Optimized Packages](https://i.imgur.com/nL1l7WI.png)\n\naccording to [1] the best model is Random Forest with balanced feature selection data. it's has Accuracy 82%, Precision 84%, Recall 82% and F1-Score 81%. \n\n<br>\n\n\nThe goal of this kernel is to beat The benchmark with  :\n- Convert dataset to Machine Learning friendly (Feature Engginering)\n- Develop XGBoost model to predict whether a loan is a good or bad risk.\n- Find the Best parameter for XGBoost Model (Hyperparameter Tunning)\n- Beat the Benchmark"
  },
  {
   "metadata": {
    "id": "BFIDjGe8BNiZ",
    "colab_type": "text",
    "_uuid": "12bfcccb8223f3c0039be46a701bff6b3311eb74"
   },
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "id": "kqRSZpTCfG10",
    "colab_type": "text",
    "_uuid": "63a5648103f48c821752a5b1f403dfb477159180"
   },
   "cell_type": "markdown",
   "source": "# Table of Content\n\n**1. [Introduction](#Introduction)** <br>\n    - Import Library\n    - Evaluation Function\n    - XGBoost Model\n**2. [Preprocess](#Preprocess)** <br>\n    - Importing Dataset\n    - StandardScaler\n    - Encoding Categorical Feature\n    - Concate Transformed Dataset\n    - Split Training Dataset\n    - XGBoost  1a: Unbalance Dataset (Base Model: ROC_AUC:0.74)\n    - XGBoost  1b: Unbalance Dataset (ROC_AUC:0.79)\n**3. [Balanced Dataset](#Balanced Dataset)** <br>    \n    - XGBoost 2a: Balanced (Base Model: ROC_AUC:0.77)\n    - **XGBoost 2b: Balanced (ROC_AUC:0.80)**\n**4. [Others](#Others)** <br>  \n    - Lighgbm (ROC_AUC:0.73)\n    - LogisticRegression (ROC_AUC:0.77)\n    - RandomForestClassifier (ROC_AUC:0.69)\n    - ExtraTreesClassifier (ROC_AUC:0.74)\n    - DecisionTreeClassifier (ROC_AUC:0.64)\n    - GradientBoostingClassifier (ROC_AUC:0.76)\n    - AdaBoostClassifier (ROC_AUC:0.72)"
  },
  {
   "metadata": {
    "id": "BwWgAWVLC2Ln",
    "colab_type": "text",
    "_uuid": "afe3100b12ba5779b15f698a1975eaab170742c4"
   },
   "cell_type": "markdown",
   "source": "<a id=\"Introduction\"></a> <br>\n# **1. Introduction:** \n- Import Library\n- Evaluation Function\n- XGBoost Model"
  },
  {
   "metadata": {
    "id": "oZH67UWnA915",
    "colab_type": "text",
    "_uuid": "86c6a56e4b0988d902401370b957f63f4f2754f1"
   },
   "cell_type": "markdown",
   "source": "### Import Library"
  },
  {
   "metadata": {
    "id": "UQUQbCn-LIjR",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "trusted": true,
    "_uuid": "fa1b3ac82eb8fe1b02d69fab3a10b621f1392484",
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "#Importing necessary packages in Python \n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np ; np.random.seed(sum(map(ord, \"aesthetics\")))\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_curve, roc_auc_score, auc, accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit,train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize, StandardScaler, MinMaxScaler\n",
    "\n",
    "import seaborn \n",
    "seaborn.set_context('notebook') \n",
    "seaborn.set_style(style='darkgrid')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "HvfBj0KiBC1m",
    "colab_type": "text",
    "_uuid": "e53977fea8ba2969bb815820b810ae0798f79ff3"
   },
   "cell_type": "markdown",
   "source": "### Evaluation Function\n"
  },
  {
   "metadata": {
    "id": "Y5FAGSW_K_il",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "trusted": true,
    "collapsed": true,
    "_uuid": "ad532098b4568aab69e710aa1b73097b0aeaa56a"
   },
   "cell_type": "code",
   "source": "# Function for evaluation reports\ndef get_eval1(clf, X,y):\n    # Cross Validation to test and anticipate overfitting problem\n    scores1 = cross_val_score(clf, X, y, cv=2, scoring='accuracy')\n    scores2 = cross_val_score(clf, X, y, cv=2, scoring='precision')\n    scores3 = cross_val_score(clf, X, y, cv=2, scoring='recall')\n    scores4 = cross_val_score(clf, X, y, cv=2, scoring='roc_auc')\n    \n    # The mean score and standard deviation of the score estimate\n    print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std()))\n    print(\"Cross Validation Precision: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std()))\n    print(\"Cross Validation Recall: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std()))\n    print(\"Cross Validation roc_auc: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std()))\n    \n    return \n\ndef get_eval2(clf, X_train, y_train,X_test, y_test):\n    # Cross Validation to test and anticipate overfitting problem\n    scores1 = cross_val_score(clf, X_test, y_test, cv=2, scoring='accuracy')\n    scores2 = cross_val_score(clf, X_test, y_test, cv=2, scoring='precision')\n    scores3 = cross_val_score(clf, X_test, y_test, cv=2, scoring='recall')\n    scores4 = cross_val_score(clf, X_test, y_test, cv=2, scoring='roc_auc')\n    \n    # The mean score and standard deviation of the score estimate\n    print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std()))\n    print(\"Cross Validation Precision: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std()))\n    print(\"Cross Validation Recall: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std()))\n    print(\"Cross Validation roc_auc: %0.2f (+/- %0.2f)\" % (scores4.mean(), scores4.std()))\n    \n    return  \n  \n# Function to get roc curve\ndef get_roc (y_test,y_pred):\n    # Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    fpr, tpr, _ = roc_curve(y_test, y_pred)\n    roc_auc = auc(fpr, tpr)\n    #Plot of a ROC curve\n    plt.figure()\n    lw = 2\n    plt.plot(fpr, tpr, color='darkorange',\n             label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"upper left\")\n    plt.show()\n    return\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "ktQtae8aBGPQ",
    "colab_type": "text",
    "_uuid": "148a2b3cfebaac7674b5bb78496d1cf0266a26cf"
   },
   "cell_type": "markdown",
   "source": "#### XGBoost Model"
  },
  {
   "metadata": {
    "id": "qOM2Y0A8CGN8",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "trusted": true,
    "collapsed": true,
    "_uuid": "a7b80d642ccc18e23b9a0ece9c7f57eca3c67cfd"
   },
   "cell_type": "code",
   "source": "import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\n#print('XGBoost v',xgb.__version__)\n\n# fit, train and cross validate Decision Tree with training and test data \ndef xgbclf(params, X_train, y_train,X_test, y_test):\n  \n    eval_set=[(X_train, y_train), (X_test, y_test)]\n    \n    model = XGBClassifier(**params).\\\n      fit(X_train, y_train, eval_set=eval_set, \\\n                  eval_metric='auc', early_stopping_rounds = 100, verbose=100)\n        \n    #print(model.best_ntree_limit)\n\n    model.set_params(**{'n_estimators': model.best_ntree_limit})\n    model.fit(X_train, y_train)\n    #print(model,'\\n')\n    \n    # Predict target variables y for test data\n    y_pred = model.predict(X_test, ntree_limit=model.best_ntree_limit) #model.best_iteration\n    #print(y_pred)\n   \n    # Get Cross Validation and Confusion matrix\n    #get_eval(model, X_train, y_train)\n    #get_eval2(model, X_train, y_train,X_test, y_test)\n    \n    # Create and print confusion matrix    \n    abclf_cm = confusion_matrix(y_test,y_pred)\n    print(abclf_cm)\n    \n    #y_pred = model.predict(X_test)\n    print (classification_report(y_test,y_pred) )\n    print ('\\n')\n    print (\"Model Final Generalization Accuracy: %.6f\" %accuracy_score(y_test,y_pred) )\n    \n    # Predict probabilities target variables y for test data\n    y_pred_proba = model.predict_proba(X_test, ntree_limit=model.best_ntree_limit)[:,1] #model.best_iteration\n    get_roc (y_test,y_pred_proba)\n    return model\n\ndef plot_featureImportance(model, keys):\n  importances = model.feature_importances_\n\n  importance_frame = pd.DataFrame({'Importance': list(importances), 'Feature': list(keys)})\n  importance_frame.sort_values(by = 'Importance', inplace = True)\n  importance_frame.tail(10).plot(kind = 'barh', x = 'Feature', figsize = (8,8), color = 'orange')",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "b9VmiiUDCvRV",
    "colab_type": "text",
    "_uuid": "2e8d5ce5e9daf39d851ca53856f640a90156745a"
   },
   "cell_type": "markdown",
   "source": "<a id=\"Preprocess\"></a> <br>\n# **2. Preprocess** \n- Importing Dataset\n- StandardScaler\n- Encoding Categorical Feature\n- Concate Transformed Dataset\n- Split Training Dataset\n- XGBoost  1a: Unbalance Dataset (Base Model: ROC_AUC:0.74)\n- XGBoost  1b: Unbalance Dataset (ROC_AUC:0.79)"
  },
  {
   "metadata": {
    "id": "L4G0iMwfKb4J",
    "colab_type": "text",
    "_uuid": "366cfb21b371f12c5bbf005342de219717fde974"
   },
   "cell_type": "markdown",
   "source": "### Import Dataset\n\nOK let's get started. We'll download the data from the UCI website."
  },
  {
   "metadata": {
    "id": "YYgBTbPj1fbQ",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "outputId": "d5569d76-1c4f-432a-a2b7-2b9ceb3e3439",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1531200575113,
     "user_tz": -420,
     "elapsed": 768,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "4807a2a54ddeb7ecb9142b586088ea672103d4ff",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "file = '../input/germancreditdata/german.data'\nurl = \"http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n\nnames = ['existingchecking', 'duration', 'credithistory', 'purpose', 'creditamount', \n         'savings', 'employmentsince', 'installmentrate', 'statussex', 'otherdebtors', \n         'residencesince', 'property', 'age', 'otherinstallmentplans', 'housing', \n         'existingcredits', 'job', 'peopleliable', 'telephone', 'foreignworker', 'classification']\n\ndata = pd.read_csv(file,names = names, delimiter=' ')\nprint(data.shape)\nprint (data.columns)\ndata.head(10)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "B3FPJfz33xkK",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "outputId": "9c678580-fb5a-4f2c-a788-676f3fda2d60",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1531189108051,
     "user_tz": -420,
     "elapsed": 709,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "224c2c3967abdccd1e4527c18024e08288ba1ca9",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "# Binarize the y output for easier use of e.g. ROC curves -> 0 = 'bad' credit; 1 = 'good' credit\ndata.classification.replace([1,2], [1,0], inplace=True)\n# Print number of 'good' credits (should be 700) and 'bad credits (should be 300)\ndata.classification.value_counts()",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "Tr1A8ZIHzuFw",
    "colab_type": "text",
    "_uuid": "2d2774790c3f63cfc0eaa81517ce8f0eb4680478"
   },
   "cell_type": "markdown",
   "source": "### StandardScaler"
  },
  {
   "metadata": {
    "id": "dKKUEqTo380x",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "trusted": true,
    "_uuid": "f03a76714ee08fe41f9b59aab287d68d481892b5",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "#numerical variables labels\nnumvars = ['creditamount', 'duration', 'installmentrate', 'residencesince', 'age', \n           'existingcredits', 'peopleliable', 'classification']\n\n# Standardization\nnumdata_std = pd.DataFrame(StandardScaler().fit_transform(data[numvars].drop(['classification'], axis=1)))",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "X4ZzfmRy4M9I",
    "colab_type": "text",
    "_uuid": "19dce81fc16194265c5d8942fa81c64934d60855"
   },
   "cell_type": "markdown",
   "source": "### Encoding Categorical Feature\n\nLabelencoding to transform categorical to numerical, Enables better Visualization than one hot encoding"
  },
  {
   "metadata": {
    "id": "xSnUU8E_4IgX",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "outputId": "4325e306-c15b-4130-ee8b-105729ccd053",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1531189110846,
     "user_tz": -420,
     "elapsed": 621,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "dab67695a0984af965a7dbea250276c4369b5875",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "from collections import defaultdict\n\n#categorical variables labels\ncatvars = ['existingchecking', 'credithistory', 'purpose', 'savings', 'employmentsince',\n           'statussex', 'otherdebtors', 'property', 'otherinstallmentplans', 'housing', 'job', \n           'telephone', 'foreignworker']\n\nd = defaultdict(LabelEncoder)\n\n# Encoding the variable\nlecatdata = data[catvars].apply(lambda x: d[x.name].fit_transform(x))\n\n# print transformations\nfor x in range(len(catvars)):\n    print(catvars[x],\": \", data[catvars[x]].unique())\n    print(catvars[x],\": \", lecatdata[catvars[x]].unique())\n\n#One hot encoding, create dummy variables for every category of every categorical variable\ndummyvars = pd.get_dummies(data[catvars])",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "R3OBrifU4Zpb",
    "colab_type": "text",
    "_uuid": "6a15498bdd45a6b2d0c88edbe3059744294396c6"
   },
   "cell_type": "markdown",
   "source": "### Concate Transformed Dataset\nappend the dummy variable of the initial numerical variables numvars# append "
  },
  {
   "metadata": {
    "id": "jkncbC1M4ZzD",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "outputId": "4b596160-48a6-40c5-8fd2-2104e3afabe9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1531189111653,
     "user_tz": -420,
     "elapsed": 638,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "50738e0e4b89a8facc7c73581661f3110427d8e9",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "data_clean = pd.concat([data[numvars], dummyvars], axis = 1)\n\nprint(data_clean.shape)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "OI89YwDN4kXI",
    "colab_type": "text",
    "_uuid": "53f8db9397eeb56dae3d735e712b4ba251a36a7b"
   },
   "cell_type": "markdown",
   "source": "### Split Training Dataset"
  },
  {
   "metadata": {
    "id": "cP6puz7s4hQr",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "trusted": true,
    "collapsed": true,
    "_uuid": "5f1724b5dc93f592481eb1c608553d1c5fad2108"
   },
   "cell_type": "code",
   "source": "# Unscaled, unnormalized data\nX_clean = data_clean.drop('classification', axis=1)\ny_clean = data_clean['classification']\nX_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_clean,y_clean,test_size=0.2, random_state=1)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "MkEfVz7rgssR",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "outputId": "2545c4f2-9d69-4d50-dc1c-82525586f013",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1531189113358,
     "user_tz": -420,
     "elapsed": 708,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "900557195bd519524bb3d46fb6b3d8d7344692dc",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "X_train_clean.keys()",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "3LRHY79JAlbF",
    "colab_type": "text",
    "_uuid": "924ad3aaf8f771939fafab52352598b158d4d9bb"
   },
   "cell_type": "markdown",
   "source": "### XGBoost  1a: Unbalance Dataset (Base Model: ROC_AUC:0.74)"
  },
  {
   "metadata": {
    "id": "trS6OdaaEoKL",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1039
    },
    "outputId": "38c94f83-752e-4e6d-8439-b42692b6f9f1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1531192485583,
     "user_tz": -420,
     "elapsed": 1831,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "03740b4aa1ec34f7874001fe00f36496a607050b",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "params={}\nxgbclf(params, X_train_clean, y_train_clean, X_test_clean, y_test_clean)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "10ebb57456ac4233b77b1ad284c15984aee73a1c"
   },
   "cell_type": "markdown",
   "source": "### XGBoost  1b: Unbalance Dataset (ROC_AUC:0.79)"
  },
  {
   "metadata": {
    "trusted": true,
    "_uuid": "9b27e5641d57347d244ebc33a634c35a3a8e0947",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "params={}\n\nparams1={\n    'n_estimators':3000,\n    'objective': 'binary:logistic',\n    'learning_rate': 0.05,\n    'gamma':0.1,\n    'subsample':0.8,\n    'colsample_bytree':0.3,\n    'min_child_weight':3,\n    'max_depth':3,\n    #'seed':1024,\n    'n_jobs' : -1\n}\n\nparams2={\n    'n_estimators':3000,\n    'objective': 'binary:logistic',\n    'learning_rate': 0.005,\n    #'gamma':0.01,\n    'subsample':0.555,\n    'colsample_bytree':0.7,\n    'min_child_weight':3,\n    'max_depth':8,\n    #'seed':1024,\n    'n_jobs' : -1\n}\n\nxgbclf(params2, X_train_clean, y_train_clean, X_test_clean, y_test_clean)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "bFxEnRYVD_Xe",
    "colab_type": "text",
    "_uuid": "b14d322c24858a4b4ec4656bd96eb3a1843802e1"
   },
   "cell_type": "markdown",
   "source": "<a id=\"Balanced Dataset\"></a> <br>\n# **3. Balanced Dataset** \n- XGBoost 2a: Balanced (Base Model: ROC_AUC:0.77)\n- XGBoost 2b: Balanced (ROC_AUC:0.80)"
  },
  {
   "metadata": {
    "id": "5NEgnXdM1U0J",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "outputId": "d3404eb4-ed88-46ea-ab18-60b259a22ed2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1531189121767,
     "user_tz": -420,
     "elapsed": 664,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "bfba5a9de83536e8ee9635d98339dfd33b7d657a",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "\nfrom imblearn.over_sampling import SMOTE\n\n# Oversampling\n# http://contrib.scikit-learn.org/imbalanced-learn/auto_examples/combine/plot_smote_enn.html#sphx-glr-auto-examples-combine-plot-smote-enn-py\n\n# Apply SMOTE\nsm = SMOTE(ratio='auto')\nX_train_clean_res, y_train_clean_res = sm.fit_sample(X_train_clean, y_train_clean)\n\n# Print number of 'good' credits and 'bad credits, should be fairly balanced now\nprint(\"Before/After clean\")\nunique, counts = np.unique(y_train_clean, return_counts=True)\nprint(dict(zip(unique, counts)))\nunique, counts = np.unique(y_train_clean_res, return_counts=True)\nprint(dict(zip(unique, counts)))",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "h2-muneU1U9H",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "trusted": true,
    "collapsed": true,
    "_uuid": "b8a7a3c79685af31aecb2ade360415f92a30460b"
   },
   "cell_type": "code",
   "source": "#Great, before we do anything else, let's split the data into train/test.\nX_train_clean_res = pd.DataFrame(X_train_clean_res, columns=X_train_clean.keys())\n#y_train_clean_res = pd.DataFrame(y_train_clean_res)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "C-yIxVQkUZyW",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "outputId": "ae623e97-04e8-4417-8311-3da47f9b94e3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1531189123494,
     "user_tz": -420,
     "elapsed": 695,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "3a8b147901159dc4ac09fa2efd4d5d9578f97b99",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "print(np.shape(X_train_clean_res))\nprint(np.shape(y_train_clean_res))\nprint(np.shape(X_test_clean)) \nprint(np.shape(y_test_clean))",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "04626b0c29b5a77a013fedfee30b55b4d92b684b"
   },
   "cell_type": "markdown",
   "source": "### XGBoost 2a: Balanced (Base Model: ROC_AUC:0.77)"
  },
  {
   "metadata": {
    "id": "NQ5P5oG0IwIS",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "outputId": "3f402469-f7d9-496d-e772-059ef4ef0aec",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1531189328790,
     "user_tz": -420,
     "elapsed": 1321,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "ca524e248c28f147289605a30f68b11ecabe4559",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "#BASE MODEL\nparams={}\nxgbclf(params,X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "RjlSw9En1P4p",
    "colab_type": "text",
    "_uuid": "71a3040a7d73bfa3aba166e10d804f9257d8bde8"
   },
   "cell_type": "markdown",
   "source": "### XGBoost 2b: Balanced (ROC_AUC:0.80)"
  },
  {
   "metadata": {
    "id": "x9PHpLlJoNFz",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1403
    },
    "outputId": "ed2910d2-4508-49d9-d1be-575c07625fb6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1531192901612,
     "user_tz": -420,
     "elapsed": 2539,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "11855f908fb13b97d120ea375c75ab13885d9e43",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "params = {}\n\nparams1={\n    'n_estimators':3000,\n    'objective': 'binary:logistic',\n    'learning_rate': 0.05,\n    'gamma':0.1,\n    'subsample':0.8,\n    'colsample_bytree':0.3,\n    'min_child_weight':3,\n    'max_depth':3,\n    #'seed':1024,\n    'n_jobs' : -1\n}\n\nparams2={\n    'n_estimators':3000,\n    'objective': 'binary:logistic',\n    'learning_rate': 0.005,\n    #'gamma':0.01,\n    'subsample':0.555,\n    'colsample_bytree':0.7,\n    'min_child_weight':3,\n    'max_depth':8,\n    #'seed':1024,\n    'n_jobs' : -1\n}\n\n#xgbclf(params, X_train, y_train,X_test,y_test)\nmodel = xgbclf(params2,X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)\nmodel\n#plot_featureImportance(model, X_train_clean_res.keys())",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "T0uGUXyUa4h_",
    "colab_type": "text",
    "_uuid": "518227609cbeb12fa67390bd5a097ddc7bd2f71a"
   },
   "cell_type": "markdown",
   "source": "# 4.  Feature Selection\n- XGBoost3 (Base Model:ROC_AUC:0.73)\n- GridSearchCV (ROC_AUC:0.70)"
  },
  {
   "metadata": {
    "id": "vOISYxySN4qJ",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "trusted": true,
    "collapsed": true,
    "_uuid": "c9da497ba8de093a285cf4ffbec4535219c74466"
   },
   "cell_type": "code",
   "source": "#model = xgbclf(params1,X_train_clean_res[importance_col], y_train_clean_res,X_test_clean[importance_col], y_test_clean)\n\nimportances = model.feature_importances_\nimportance_frame = pd.DataFrame({'Importance': list(importances), 'Feature': list(X_train_clean_res.keys())})\nimportance_frame.sort_values(by = 'Importance', inplace = True, ascending=False)\nimportance_col = importance_frame.Feature.head(10).values",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "a2ce51442a79c7a28776f90153e4107737183abd"
   },
   "cell_type": "markdown",
   "source": "### XGBoost3 (Base Model:ROC_AUC:0.73)"
  },
  {
   "metadata": {
    "id": "LwqK7dpAX7nn",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1056
    },
    "outputId": "e4689e0c-52b0-476a-b84c-e47da4028a37",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1531195815598,
     "user_tz": -420,
     "elapsed": 1923,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "17ef3ab68a22b1af2a31b58e0a452a72e0db19bd",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "params = {}\n\nparams1={\n    'n_estimators':3000,\n    'objective': 'binary:logistic',\n    'learning_rate': 0.01,\n    #'gamma':0.1,\n    #'subsample':0.8,\n    #'colsample_bytree':0.3,\n    #'min_child_weight':3,\n    'max_depth':3,\n    #'seed':1024,\n    'n_jobs' : -1\n}\n\nxgbclf(params,X_train_clean_res[importance_col], y_train_clean_res,X_test_clean[importance_col], y_test_clean)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "Wxgbu6HbrstB",
    "colab_type": "text",
    "_uuid": "f8037e33ee37292b23413304ceff57026c6b49e1"
   },
   "cell_type": "markdown",
   "source": "### GridSearchCV (ROC_AUC:0.70)"
  },
  {
   "metadata": {
    "id": "m7lf_As9oUvh",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "outputId": "6ff51851-0fe9-4c53-c5cf-315fa84143e4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1531196561870,
     "user_tz": -420,
     "elapsed": 3066,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "105346b26c0fe9e4cba1b68b6194be9d70b50701",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "from sklearn.grid_search import GridSearchCV\n\nprint('XGBoost with grid search')\n# play with these params\nparams={\n    'learning_rate': [0.01, 0.02],\n    'max_depth': [3], # 5 is good but takes too long in kaggle env\n    #'subsample': [0.6], #[0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n    #'colsample_bytree': [0.5], #[0.5,0.6,0.7,0.8],\n    'n_estimators': [50, 100, 200, 300, 400, 500]\n    #'reg_alpha': [0.03] #[0.01, 0.02, 0.03, 0.04]\n}\n\n\nxgb_clf = xgb.XGBClassifier()\n\nrs = GridSearchCV(xgb_clf,\n                  params,\n                  cv=2,\n                  scoring=\"roc_auc\",\n                  n_jobs=1,\n                  verbose=False)\nrs.fit(X_train_clean_res[importance_col], y_train_clean_res)\nbest_est = rs.best_estimator_\nprint(best_est)\nprint(rs.best_score_)\n\n# Roc AUC with test data\nprint(rs.score(X_test_clean[importance_col],y_test_clean))\n\n# Roc AUC with all train data\n#y_pred_proba = best_est.predict_proba(X_test_clean[importance_col])[:,1]\n#print(\"Roc AUC: \", roc_auc_score(y_test_clean, y_pred_proba))\n\n#xgbclf(params1,X_train_clean_res[importance_col], y_train_clean_res,X_test_clean[importance_col], y_test_clean)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "d2fe0b7ea9b605569bdfa60b39faf7d6965bfde0"
   },
   "cell_type": "markdown",
   "source": "<a id=\"Others\"></a> <br>\n# 5. Others\n- Lighgbm (ROC_AUC:0.73)\n- LogisticRegression (ROC_AUC:0.77)\n- RandomForestClassifier (ROC_AUC:0.69)\n- ExtraTreesClassifier (ROC_AUC:0.74)\n- DecisionTreeClassifier (ROC_AUC:0.64)\n- GradientBoostingClassifier (ROC_AUC:0.76)\n- AdaBoostClassifier (ROC_AUC:0.72)"
  },
  {
   "metadata": {
    "id": "Pce2PcrQryuY",
    "colab_type": "text",
    "_uuid": "360450a8797f752a9d9b09a4c4a16d72dbe0b071"
   },
   "cell_type": "markdown",
   "source": "### Lighgbm (ROC_AUC:0.73)"
  },
  {
   "metadata": {
    "trusted": true,
    "_uuid": "432aa50546f660ed1ae9b4ab064bbea7b6f54e03",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n\nimport lightgbm as lgb\n\n# fit, train and cross validate Decision Tree with training and test data \ndef lgbclf(X_train, y_train,X_test, y_test):\n\n    model = lgb.LGBMClassifier().fit(X_train, y_train)\n    print(model,'\\n')\n\n    # Predict target variables y for test data\n    y_pred = model.predict_proba(X_test)[:,1]\n\n    # Get Cross Validation and Confusion matrix\n    #get_eval(model, X_train, y_train,y_test,y_pred)\n    #get_eval2(model, X_train, y_train,X_test, y_test,y_pred)\n    get_roc (y_test,y_pred)\n    return\n\n# Logistic Regression\n#lgbclf(X_train, y_train,X_test,y_test)\nlgbclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "tzhgWR1hry3s",
    "colab_type": "text",
    "_uuid": "318b9364794e6f1e2da5550bf961885bdccc5825"
   },
   "cell_type": "markdown",
   "source": "### LogisticRegression (ROC_AUC:0.77)"
  },
  {
   "metadata": {
    "trusted": true,
    "_uuid": "e0b612a0bab5b2f06e038f37b35868716f97bd00",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "from sklearn.linear_model import LogisticRegression\n\n# fit, train and cross validate Decision Tree with training and test data \ndef logregclf(X_train, y_train,X_test, y_test):\n    print(\"LogisticRegression\")\n    model = LogisticRegression().fit(X_train, y_train)\n    print(model,'\\n')\n\n    # Predict target variables y for test data\n    y_pred = model.predict_proba(X_test)[:,1]\n\n    # Get Cross Validation and Confusion matrix\n    #get_eval(model, X_train, y_train,y_test,y_pred)\n    #get_eval2(model, X_train, y_train,X_test, y_test,y_pred)\n    get_roc (y_test,y_pred)\n    return\n\n# Logistic Regression\n#logregclf(X_train, y_train,X_test,y_test)\nlogregclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "e95e51b587054a97daf75be89cd308b615feb8ca"
   },
   "cell_type": "markdown",
   "source": "### RandomForestClassifier (ROC_AUC:0.69)"
  },
  {
   "metadata": {
    "trusted": true,
    "_uuid": "4b9f601bd07ff3253da4d89352ebd785fc3eeac2",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "from sklearn.ensemble import RandomForestClassifier \n\n# fit, train and cross validate Decision Tree with training and test data \ndef randomforestclf(X_train, y_train,X_test, y_test):\n    print(\"RandomForestClassifier\")\n    randomforest = RandomForestClassifier().fit(X_train, y_train)\n    print(randomforest,'\\n')\n    \n    # Predict target variables y for test data\n    y_pred = randomforest.predict_proba(X_test)[:,1]\n\n    # Get Cross Validation and Confusion matrix\n    #get_eval(randomforest, X_train, y_train,y_test,y_pred)\n    get_roc (y_test,y_pred)\n    return\n\n# Random Forest\n# Choose clean data, as tree is robust\nrandomforestclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "75fb46bd9b0ac1493449c6451b2f8a85974d4f86"
   },
   "cell_type": "markdown",
   "source": "### ExtraTreesClassifier (ROC_AUC:0.74)"
  },
  {
   "metadata": {
    "trusted": true,
    "_uuid": "28df42b00dedfda6ffcfb8235ff0ad2ef42a4bec",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "from sklearn.ensemble import ExtraTreesClassifier\n\n# fit, train and cross validate Decision Tree with training and test data \ndef extratreesclf(X_train, y_train,X_test, y_test):\n    print(\"ExtraTreesClassifier\")\n    extratrees = ExtraTreesClassifier().fit(X_train, y_train)\n    print(extratrees,'\\n')\n    \n    # Predict target variables y for test data\n    y_pred = extratrees.predict_proba(X_test)[:,1]\n\n    # Get Cross Validation and Confusion matrix\n    #get_eval(extratrees, X_train, y_train,y_test,y_pred)\n    \n    get_roc (y_test,y_pred)\n    return\n \n# Extra Trees\n# Choose clean data, as tree is robust\nextratreesclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "d08be5c932aa326666c8865f5c1ce15f5f7984b4"
   },
   "cell_type": "markdown",
   "source": "### DecisionTreeClassifier (ROC_AUC:0.64)"
  },
  {
   "metadata": {
    "trusted": true,
    "_uuid": "07c8334d26469b64ded21db507d7d246d0ba05f6",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "from sklearn.tree import DecisionTreeClassifier \n# fit, train and cross validate Decision Tree with training and test data \ndef dectreeclf(X_train, y_train,X_test, y_test):\n    print(\"DecisionTreeClassifier\")\n    dec_tree = DecisionTreeClassifier(min_samples_split=10,min_samples_leaf=5).fit(X_train, y_train)\n    print(dec_tree,'\\n')\n    \n    # Predict target variables y for test data\n    y_pred = dec_tree.predict_proba(X_test)[:,1]\n\n    \n    # Get Cross Validation and Confusion matrix\n    #get_eval(dec_tree, X_train, y_train,y_test,y_pred)\n    get_roc (y_test,y_pred)\n    return\n\n# Decisiontree\ndectreeclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "nA3tHbQDry_f",
    "colab_type": "text",
    "_uuid": "4ed9e0b8545196403507dde0a878ba1a5f7cc604"
   },
   "cell_type": "markdown",
   "source": "### GradientBoostingClassifier (ROC_AUC:0.76)"
  },
  {
   "metadata": {
    "id": "JjxG_CYtekIA",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "outputId": "42c5bdfd-94d2-47fd-e82b-7a9a5e664528",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1530921188337,
     "user_tz": -420,
     "elapsed": 5896,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "72b88670afd0ba8487d1a3a98bbecde61427aa4f",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "from sklearn.ensemble import GradientBoostingClassifier\n\n# fit, train and cross validate GradientBoostingClassifier with training and test data \ndef gradientboostingclf(X_train, y_train, X_test, y_test):  \n    print(\"GradientBoostingClassifier\")\n    gbclf = GradientBoostingClassifier().fit(X_train, y_train)\n    print(gbclf,'\\n')\n    \n    # Predict target variables y for test data\n    y_pred = gbclf.predict_proba(X_test)[:,1]\n\n    # Get Cross Validation and Confusion matrix\n    #get_eval(gbclf, X_train, y_train,y_test,y_pred)\n    get_roc (y_test,y_pred)\n    return\n  \n# GradientBoostingClassifier\n# Choose clean data, as tree is robust\ngradientboostingclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "e2d254a8b7a76f3fcd3f98277a52989c5df7d0c2"
   },
   "cell_type": "markdown",
   "source": "### AdaBoostClassifier (ROC_AUC:0.75)"
  },
  {
   "metadata": {
    "id": "wdN9GgUUetH1",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "outputId": "127b3cf9-a597-4d63-f296-b4ceeb0d6a19",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1530921206830,
     "user_tz": -420,
     "elapsed": 4970,
     "user": {
      "displayName": "M Hendra Herviawan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116685199798904688878"
     }
    },
    "trusted": true,
    "_uuid": "c8caa356aa7993faa1bd77afafd858b7f95e18b8",
    "collapsed": true
   },
   "cell_type": "code",
   "source": "from sklearn.ensemble import AdaBoostClassifier\n\n# fit, train and cross validate GradientBoostingClassifier with training and test data \ndef adaboostclf(X_train, y_train, X_test, y_test):  \n    print(\"AdaBoostClassifier\")\n    abclf = AdaBoostClassifier().fit(X_train, y_train)\n    print(abclf,'\\n')\n    \n    # Predict target variables y for test data\n    y_pred = abclf.predict_proba(X_test)[:,1]\n\n    # Get Cross Validation and Confusion matrix\n    #get_eval(abclf, X_train, y_train,y_test,y_pred)\n    get_roc (y_test,y_pred)\n    return\n\n# AdaBoostClassifier\n# Choose clean data, as tree is robust\nadaboostclf(X_train_clean_res, y_train_clean_res,X_test_clean, y_test_clean)",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "german-credit_XGB1.ipynb",
   "version": "0.3.2",
   "views": {},
   "default_view": {},
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
