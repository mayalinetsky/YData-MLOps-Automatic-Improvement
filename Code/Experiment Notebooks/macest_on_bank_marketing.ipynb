{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Improving Model Performance Using MACEst on the Bank Marketing Dataset \n",
    "===\n",
    "\n",
    "This notebook will test weather MACEst can be used in order to improve the ROC-AUC score of a trained model on the bank marketing dataset."
   ],
   "id": "237c28fccac8d3f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "MACEst requires the following 'batches' of data (see [here](https://github.com/oracle/macest?tab=readme-ov-file#classification)):\n",
    "1. Regular Training Collection (34%)\n",
    "2. Confidence Collection: (66%)\n",
    "   * conf_train (33%)\n",
    "   * cal (33%)\n",
    "      * cal_train (16.5%)\n",
    "      * cal_test  (16.5%)\n",
    "\n",
    "So in order to make sure the non-improved model and the improved model are evaluated correctly, we'll train both models on the same data and test on the same data."
   ],
   "id": "fa2bb41ff2d256f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Loading, Preprocessing and Splitting",
   "id": "adfcde4d1560e47"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-12T15:37:42.621094Z",
     "start_time": "2024-07-12T15:37:25.349867Z"
    }
   },
   "source": [
    "from data_acquisition.bank_marketing_loading import load_bank_marketing_dataset\n",
    "from modeling.xgboost_bank_marketing_impl import preprocess_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bank_marketing_raw_data_df = load_bank_marketing_dataset()\n",
    "\n",
    "data_X, data_y = preprocess_data(bank_marketing_raw_data_df)\n",
    "\n",
    "X_regular_train, X_conf, y_regular_train, y_conf  = train_test_split(data_X,\n",
    "                                                                     data_y,\n",
    "                                                                     stratify=data_y,\n",
    "                                                                     test_size=0.66,\n",
    "                                                                     random_state=10)\n",
    "\n",
    "X_conf_train, X_cal, y_conf_train, y_cal = train_test_split(X_conf,\n",
    "                                                            y_conf,\n",
    "                                                            stratify=y_conf,\n",
    "                                                            test_size=0.5,\n",
    "                                                            random_state=0)\n",
    "\n",
    "X_cal_train, X_cal_test, y_cal_train,  y_cal_test = train_test_split(X_cal,\n",
    "                                                                     y_cal,\n",
    "                                                                     stratify=y_cal,\n",
    "                                                                     test_size=0.5,\n",
    "                                                                     random_state=0)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training Probabilistic XGBoost on the Bank Marketing Dataset",
   "id": "159499096f2e0f4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T15:37:44.003295Z",
     "start_time": "2024-07-12T15:37:42.623070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import xgboost\n",
    "import pandas as pd\n",
    "from modeling.xgboost_bank_marketing_impl import train_model, evaluate_predictions_roc_auc_score\n",
    "\n",
    "no_macest_train_X = pd.concat([X_regular_train, X_conf_train, X_cal_train])\n",
    "no_macest_train_y = pd.concat([y_regular_train, y_conf_train, y_cal_train])\n",
    "\n",
    "# test set is the same: cal_test\n",
    "no_macest_xgboost = train_model(no_macest_train_X, no_macest_train_y)\n",
    "\n",
    "no_macest_test_preds = no_macest_xgboost.predict(xgboost.DMatrix(X_cal_test))\n",
    "no_macest_roc_auc_score_val = evaluate_predictions_roc_auc_score(y_cal_test, no_macest_test_preds)\n",
    "print(f\"ROC AUC Score for XGBoost without MACEst: {no_macest_roc_auc_score_val}\")"
   ],
   "id": "f513de570312f1ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training\n",
      "[18:37:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_dept\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Finished training\n",
      "ROC AUC Score for XGBoost without MACEst: 0.9284442313798231\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training Probabilistic XGBoost on the Bank Marketing Dataset with MACEst\n",
    "Because MACEst package supports only np.ndarrays, we'll convert all inputs as needed."
   ],
   "id": "24570b1d63da4eb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T15:41:13.848415Z",
     "start_time": "2024-07-12T15:37:49.154467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from modeling.xgboost_bank_marketing_impl import _make_predict_wrapper\n",
    "from macest.classification import models as cl_mod\n",
    "\n",
    "point_pred_model = train_model(X_regular_train.values, y_regular_train.values[:, 0])\n",
    "# wrap the predict function of the point_pred_model in order to fit the requirement of np.ndarray input into ModelWithConfidence\n",
    "point_pred_model.predict = _make_predict_wrapper(point_pred_model)\n",
    "\n",
    "macest_model = cl_mod.ModelWithConfidence(point_pred_model,\n",
    "                                      X_conf_train.values,\n",
    "                                      y_conf_train.values[:, 0])  # y_conf_train must be converted to a single dimension array\n",
    "\n",
    "macest_model.fit(X_cal_train.values, y_cal_train.values[: 0])\n",
    "print(\"After fit\")\n",
    "macest_test_preds = macest_model.predict_confidence_of_point_prediction(X_cal_test.values)\n",
    "\n",
    "macest_roc_auc_score_val = evaluate_predictions_roc_auc_score(y_cal_test, macest_test_preds)\n",
    "print(f\"ROC AUC Score for XGBoost with MACEst: {macest_roc_auc_score_val}\")"
   ],
   "id": "d7dac7c26bba1d4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training\n",
      "[18:37:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_dept\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Finished training\n",
      "In _make_predict_wrapper\n",
      "Before _make_predict_wrapper return\n",
      "Predicting normally\n",
      "Caught exception ('Expecting data to be a DMatrix object, got: ', <class 'numpy.ndarray'>)\n",
      "Predicting normally\n",
      "Caught exception ('Expecting data to be a DMatrix object, got: ', <class 'numpy.ndarray'>)\n",
      "Predicting normally\n",
      "Caught exception ('Expecting data to be a DMatrix object, got: ', <class 'numpy.ndarray'>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The map-like callable must be of the form f(func, iterable), returning a sequence of numbers the same length as 'iterable'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32mC:\\YData-MLOps-Automatic-Improvement\\venv\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py\u001B[0m in \u001B[0;36m_calculate_population_energies\u001B[1;34m(self, population)\u001B[0m\n\u001B[0;32m    877\u001B[0m             calc_energies = list(self._mapwrapper(self.func,\n\u001B[1;32m--> 878\u001B[1;33m                                                   parameters_pop[0:nfevs]))\n\u001B[0m\u001B[0;32m    879\u001B[0m             \u001B[0menergies\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mnfevs\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcalc_energies\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\YData-MLOps-Automatic-Improvement\\venv\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m   1264\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1265\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1266\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\YData-MLOps-Automatic-Improvement\\venv\\lib\\site-packages\\macest\\classification\\models.py\u001B[0m in \u001B[0;36mloss\u001B[1;34m(self, params)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mpred_conf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict_confidence_of_point_prediction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mx_cal\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mexpected_calibration_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpoint_preds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0my_cal\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpred_conf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\YData-MLOps-Automatic-Improvement\\venv\\lib\\site-packages\\macest\\classification\\models.py\u001B[0m in \u001B[0;36mpredict_confidence_of_point_prediction\u001B[1;34m(self, x_star, change_conflicts)\u001B[0m\n\u001B[0;32m    306\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 307\u001B[1;33m         \u001B[0mclass_confidence\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict_proba\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_star\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mchange_conflicts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    308\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\YData-MLOps-Automatic-Improvement\\venv\\lib\\site-packages\\macest\\classification\\models.py\u001B[0m in \u001B[0;36mpredict_proba\u001B[1;34m(self, x_star, change_conflicts)\u001B[0m\n\u001B[0;32m    278\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 279\u001B[1;33m             \u001B[0mdist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merror\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcalc_linear_distance_error_func\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclass_dist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclass_error\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    280\u001B[0m             \u001B[0mav_dist_func\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmin\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m \u001B[1;33m**\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0merror\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\YData-MLOps-Automatic-Improvement\\venv\\lib\\site-packages\\macest\\classification\\models.py\u001B[0m in \u001B[0;36mcalc_linear_distance_error_func\u001B[1;34m(self, local_distance, local_error)\u001B[0m\n\u001B[0;32m    257\u001B[0m         error = self._beta * np.average(\n\u001B[1;32m--> 258\u001B[1;33m             \u001B[0mlocal_error\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweights\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1.0\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mlocal_distance\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    259\u001B[0m         )\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36maverage\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32mC:\\YData-MLOps-Automatic-Improvement\\venv\\lib\\site-packages\\numpy\\lib\\function_base.py\u001B[0m in \u001B[0;36maverage\u001B[1;34m(a, axis, weights, returned)\u001B[0m\n\u001B[0;32m    397\u001B[0m                 raise TypeError(\n\u001B[1;32m--> 398\u001B[1;33m                     \"1D weights expected when shapes of a and weights differ.\")\n\u001B[0m\u001B[0;32m    399\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mwgt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0ma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 1D weights expected when shapes of a and weights differ.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_14944\\3296967513.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m                                       y_conf_train.values[:, 0])  # y_conf_train must be converted to a single dimension array\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m \u001B[0mmacest_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_cal_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_cal_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"After fit\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[0mmacest_test_preds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmacest_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict_confidence_of_point_prediction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_cal_test\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\YData-MLOps-Automatic-Improvement\\venv\\lib\\site-packages\\macest\\classification\\models.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x_cal, y_cal, param_range, optimiser_args)\u001B[0m\n\u001B[0;32m    395\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    396\u001B[0m         \u001B[0mtrain_helper\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_TrainingHelper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_cal\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_cal\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam_range\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 397\u001B[1;33m         \u001B[0mtrain_helper\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moptimiser_args\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moptimiser_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    398\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    399\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_check_consistent_search_method_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\YData-MLOps-Automatic-Improvement\\venv\\lib\\site-packages\\macest\\classification\\models.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, optimiser, optimiser_args)\u001B[0m\n\u001B[0;32m    596\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    597\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0moptimiser\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"de\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 598\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdifferential_evolution\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbounds\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbounds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0moptimiser_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    599\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    600\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\YData-MLOps-Automatic-Improvement\\venv\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py\u001B[0m in \u001B[0;36mdifferential_evolution\u001B[1;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol, updating, workers, constraints)\u001B[0m\n\u001B[0;32m    304\u001B[0m                                      \u001B[0mworkers\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    305\u001B[0m                                      constraints=constraints) as solver:\n\u001B[1;32m--> 306\u001B[1;33m         \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msolver\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msolve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    307\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    308\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mret\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\YData-MLOps-Automatic-Improvement\\venv\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py\u001B[0m in \u001B[0;36msolve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    743\u001B[0m             self.population_energies[self.feasible] = (\n\u001B[0;32m    744\u001B[0m                 self._calculate_population_energies(\n\u001B[1;32m--> 745\u001B[1;33m                     self.population[self.feasible]))\n\u001B[0m\u001B[0;32m    746\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    747\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_promote_lowest_energy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\YData-MLOps-Automatic-Improvement\\venv\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py\u001B[0m in \u001B[0;36m_calculate_population_energies\u001B[1;34m(self, population)\u001B[0m\n\u001B[0;32m    881\u001B[0m             \u001B[1;31m# wrong number of arguments for _mapwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    882\u001B[0m             \u001B[1;31m# or wrong length returned from the mapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 883\u001B[1;33m             raise RuntimeError(\"The map-like callable must be of the\"\n\u001B[0m\u001B[0;32m    884\u001B[0m                                \u001B[1;34m\" form f(func, iterable), returning a sequence\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    885\u001B[0m                                \" of numbers the same length as 'iterable'\")\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The map-like callable must be of the form f(func, iterable), returning a sequence of numbers the same length as 'iterable'"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
