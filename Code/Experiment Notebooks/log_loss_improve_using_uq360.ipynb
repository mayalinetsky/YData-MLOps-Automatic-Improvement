{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Improving Log Loss using IBM UQ360 blackbox MetaModel\n",
    "===\n",
    "\n",
    "https://github.com/IBM/UQ360\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html"
   ],
   "id": "ad1e82953f9836a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading the Bank Marketing Dataset",
   "id": "5dccebb5169bc318"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-13T09:58:47.232368Z",
     "start_time": "2024-07-13T09:58:43.103044Z"
    }
   },
   "source": [
    "from data_acquisition.bank_marketing_loading import load_bank_marketing_dataset\n",
    "from data_acquisition.bank_marketing_constants import DEPOSIT\n",
    "from modeling.xgboost_bank_marketing_impl import preprocess_labels\n",
    "\n",
    "bank_marketing_raw_df = load_bank_marketing_dataset()\n",
    "\n",
    "raw_X = bank_marketing_raw_df.drop(columns=[DEPOSIT])\n",
    "raw_y = bank_marketing_raw_df[DEPOSIT]\n",
    "y = preprocess_labels(raw_y)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train Test Split",
   "id": "803eb993b6817504"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T09:58:47.263943Z",
     "start_time": "2024-07-13T09:58:47.234368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_X, y, test_size=0.3, random_state=2, stratify=y)"
   ],
   "id": "e933094d838c5a04",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Log Loss of the Base Model",
   "id": "da0014b66bb519fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T09:58:48.969209Z",
     "start_time": "2024-07-13T09:58:47.264944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from modeling.xgboost_bank_marketing_impl import get_feature_preprocessor_step, get_model_for_training\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "base_model_pipeline = Pipeline(steps=[\n",
    "    ('preprocess', get_feature_preprocessor_step()),\n",
    "    ('base_model', get_model_for_training())\n",
    "])\n",
    "\n",
    "base_model_pipeline.fit(X_train, y_train)\n",
    "base_pred_test = base_model_pipeline.predict(X_test)  # shape (n_samples,)\n",
    "# base_pred_test which is the predicted integer label, can be used as probabilities in log loss because:\n",
    "# base_pred_test[i] = 0 -> probability of the positive class for sample i is 0\n",
    "# base_pred_test[i] = 1 -> probability of the positive class for sample i is 1\n",
    "base_model_log_loss_val = log_loss(y_test, base_pred_test)\n",
    "print(f\"Base Model Log Loss: {base_model_log_loss_val}\")"
   ],
   "id": "6601f31390a44812",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Log Loss: 3.707508753699377\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Log loss of the Improved Model",
   "id": "eea3478948653909"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Case 1: using UQ during training\n",
    "\n",
    "In this case the MetaModel is trained WITH the base model."
   ],
   "id": "800e0e58d0ec8082"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T09:58:53.743712Z",
     "start_time": "2024-07-13T09:58:48.971209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from uq360.algorithms.blackbox_metamodel import MetamodelClassification\n",
    "\n",
    "uq_pipeline = Pipeline(steps=[\n",
    "    ('preprocess', get_feature_preprocessor_step()),\n",
    "    ('uq_model', MetamodelClassification(base_model=get_model_for_training(), \n",
    "                                         meta_model='gbm', meta_config={},\n",
    "                                         random_seed=42))\n",
    "])\n",
    "\n",
    "uq_pipeline.fit(X_train, y_train)\n",
    "uq_pred_test, uq_pred_test_score = uq_pipeline.predict(X_test)\n",
    "\n",
    "uq_model_log_loss_val = log_loss(y_test, uq_pred_test_score)\n",
    "print(f\"UQ Model Log Loss: {uq_model_log_loss_val}\")"
   ],
   "id": "4648f28acd9255b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UQ Model Log Loss: 2.3487672914593642\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Case 2: using UQ after training\n",
    "\n",
    "In this case the MetaModel is trained AFTER the base model has already been trained."
   ],
   "id": "56f134230444a85f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T10:21:28.754797Z",
     "start_time": "2024-07-13T10:21:27.218950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# split training data into 'pre meta training' and 'meta training'\n",
    "X_pre_meta_train, X_meta_train, y_pre_meta_train, y_meta_train = train_test_split(X_train, y_train, \n",
    "                                                                                  test_size=0.2, \n",
    "                                                                                  random_state=2, \n",
    "                                                                                  stratify=y_train)\n",
    "preprocessor = get_feature_preprocessor_step().fit(X_pre_meta_train, y_pre_meta_train)\n",
    "\n",
    "# simulate trained base model\n",
    "pre_meta_base_model = get_model_for_training()\n",
    "\n",
    "base_model_trained = pre_meta_base_model.fit(preprocessor.transform(X_pre_meta_train), y_pre_meta_train)\n",
    "\n",
    "# train the meta model\n",
    "meta_model = GradientBoostingClassifier()\n",
    "\n",
    "uq_pipeline2 = Pipeline(steps=[\n",
    "    ('uq_model', MetamodelClassification(base_model=base_model_trained, \n",
    "                                         meta_model=meta_model, meta_config={},\n",
    "                                         random_seed=42))\n",
    "])\n",
    "uq_pipeline2.fit(X=None, y=None, \n",
    "                 uq_model__base_is_prefitted=True, \n",
    "                 uq_model__meta_train_data=(preprocessor.transform(X_meta_train), y_meta_train))\n",
    "\n",
    "uq2_pred_test, uq2_pred_test_score = uq_pipeline2.predict(preprocessor.transform(X_test))\n",
    "\n",
    "uq2_model_log_loss_val = log_loss(y_test, uq2_pred_test_score)\n",
    "print(f\"UQ Model Log Loss with Pre-Trained Base Model: {uq2_model_log_loss_val}\")"
   ],
   "id": "4760979ca44fc5f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UQ Model Log Loss with Pre-Trained Base Model: 2.3873139626865516\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MetaModelClassification's Effect on Log Loss\n",
    "We see that both cases saw an improvement in the log loss."
   ],
   "id": "23fea0810a6d88e4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
